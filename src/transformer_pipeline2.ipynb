{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lr.models.transformers.processor import filter_df_by_label\n",
    "from lr.models.transformers.BertWrapper import BertWrapper\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "import shutil\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"toy\"\n",
    "\n",
    "hyperparams = {\"local_rank\": -1,\n",
    "               \"max_seq_length\": 200,\n",
    "               \"overwrite_cache\": False,\n",
    "               \"num_train_epochs\":1.0,\n",
    "               \"per_gpu_train_batch_size\":32,\n",
    "               \"per_gpu_eval_batch_size\":32,\n",
    "               \"gradient_accumulation_steps\": 1,\n",
    "               \"learning_rate\":5e-5,\n",
    "               \"weight_decay\":0.0,\n",
    "               \"adam_epsilon\": 1e-8,\n",
    "               \"max_grad_norm\": 1.0,\n",
    "               \"max_steps\": 7,\n",
    "               \"warmup_steps\": 0,\n",
    "               \"save_steps\": 6,\n",
    "               \"no_cuda\":False,\n",
    "               \"n_gpu\":1,\n",
    "               \"model_name_or_path\":\"bert\",\n",
    "               \"output_dir\":\"bert\",\n",
    "               \"random_state\": 42,\n",
    "               \"fp16\":False,\n",
    "               \"fp16_opt_level\":\"01\",\n",
    "               \"device\":\"cpu\",\n",
    "               \"verbose\":False,\n",
    "               \"model_type\": \"bert\",\n",
    "               \"pad_on_left\":False,\n",
    "               \"pad_token\":0,\n",
    "               \"pad_token_segment_id\":0,\n",
    "               \"mask_padding_with_zero\":True,\n",
    "               \"eval_sample_size\":100,\n",
    "               \"n_cores\":8,\n",
    "               \"base_path\": \"data/{}/cached_\".format(folder)} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_bert = BertWrapper(hyperparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading DFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"data/{}/train.csv\".format(folder)\n",
    "test_path = \"data/{}/dev.csv\".format(folder)\n",
    "\n",
    "df = pd.read_csv(train_path)\n",
    "test = pd.read_csv(test_path)\n",
    "test = test.sample(100, random_state=hyperparams[\"random_state\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = my_bert.predict(test, transform=True, mode=\"test\")\n",
    "lmap = my_bert.processor.get_label_map()\n",
    "filtered = filter_df_by_label(test.dropna()).reset_index(drop=True)\n",
    "before_acc = np.mean(filtered.label.map(lambda x: lmap[x]) == pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step, tr_loss, train_time = my_bert.fit(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = my_bert.predict(None, transform=False,path=\"data/toy/cached_test_200\")\n",
    "lmap = my_bert.processor.get_label_map()\n",
    "filtered = filter_df_by_label(test.dropna()).reset_index(drop=True)\n",
    "after_acc = np.mean(filtered.label.map(lambda x: lmap[x]) == pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert tr_loss == 1.1454728543758392\n",
    "assert before_acc == 0.31\n",
    "assert after_acc == 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"example.log\"):\n",
    "    os.remove(\"example.log\")\n",
    "\n",
    "if os.path.exists(\"bert\"):\n",
    "    shutil.rmtree(\"bert\")\n",
    "\n",
    "    \n",
    "paths = [\"cached_dev_to_eval_200\", \"cached_test_200\", \"cached_train_200\",\n",
    "         \"cached_train_to_eval_200\"]\n",
    "\n",
    "for path in paths:\n",
    "    path = \"data/{}/{}\".format(folder, path)\n",
    "    if os.path.exists(path):\n",
    "        os.remove(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
