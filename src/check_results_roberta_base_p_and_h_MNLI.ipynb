{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results for RoBERTa when applying syn tranformation to both premise and hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display, HTML \n",
    "from lr.analysis.util import get_ts_from_results_folder \n",
    "from lr.analysis.util import get_rho_stats_from_result_list\n",
    "from lr.stats.h_testing import get_ks_stats_from_p_values_compared_to_uniform_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  3.85it/s]\n"
     ]
    }
   ],
   "source": [
    "all_accs = []\n",
    "all_transformed_accs = []\n",
    "all_paired_t_p_values = []\n",
    "all_dev_plus_diff = []\n",
    "all_time = []\n",
    "\n",
    "m_name = \"roberta_base\"\n",
    "folder = \"mnli\"\n",
    "\n",
    "test_repetitions = 4\n",
    "batchs = range(1, test_repetitions + 1)\n",
    "batchs = [1,2,3,4,6]\n",
    "\n",
    "for i in tqdm(batchs):\n",
    "    test_accuracy  = get_ts_from_results_folder(path=\"results/{}/{}/syn_p_h/batch{}/\".format(folder,m_name, i),\n",
    "                                                 stat=\"test_accuracy\")\n",
    "    \n",
    "    transformed_test_accuracy = get_ts_from_results_folder(path=\"results/{}/{}/syn_p_h/batch{}/\".format(folder,m_name, i),\n",
    "                                                           stat=\"transformed_test_accuracy\")\n",
    "    \n",
    "    paired_t_p_value  = get_ts_from_results_folder(path=\"results/{}/{}/syn_p_h/batch{}/\".format(folder,m_name, i),\n",
    "                                                    stat=\"paired_t_p_value\")\n",
    "    \n",
    "    diff  = get_ts_from_results_folder(path=\"results/{}/{}/syn_p_h/batch{}/\".format(folder,m_name, i),\n",
    "                                                    stat=\"dev_plus_accuracy_difference\")\n",
    "    \n",
    "    t_time  = get_ts_from_results_folder(path=\"results/{}/{}/syn_p_h/batch{}/\".format(folder,m_name,i),\n",
    "                                                    stat=\"test_time\")\n",
    "\n",
    "    \n",
    "    all_accs.append(test_accuracy)\n",
    "    all_transformed_accs.append(transformed_test_accuracy)\n",
    "    all_paired_t_p_values.append(paired_t_p_value)\n",
    "    all_dev_plus_diff.append(diff)\n",
    "    all_time.append(t_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.827760</td>\n",
       "      <td>0.827760</td>\n",
       "      <td>0.596020</td>\n",
       "      <td>0.829999</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.2</th>\n",
       "      <td>0.818242</td>\n",
       "      <td>0.836871</td>\n",
       "      <td>0.828880</td>\n",
       "      <td>0.328447</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.4</th>\n",
       "      <td>0.831526</td>\n",
       "      <td>0.829338</td>\n",
       "      <td>0.318217</td>\n",
       "      <td>0.828065</td>\n",
       "      <td>0.832748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.5</th>\n",
       "      <td>0.831068</td>\n",
       "      <td>0.661831</td>\n",
       "      <td>0.827607</td>\n",
       "      <td>0.328447</td>\n",
       "      <td>0.820227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.6</th>\n",
       "      <td>0.353336</td>\n",
       "      <td>0.823586</td>\n",
       "      <td>0.827709</td>\n",
       "      <td>0.830814</td>\n",
       "      <td>0.827556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.8</th>\n",
       "      <td>0.825571</td>\n",
       "      <td>0.724691</td>\n",
       "      <td>0.818344</td>\n",
       "      <td>0.328447</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.797272</td>\n",
       "      <td>0.824095</td>\n",
       "      <td>0.828422</td>\n",
       "      <td>0.328447</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     test_accuracy  test_accuracy  test_accuracy  test_accuracy  test_accuracy\n",
       "0.0       0.827760       0.827760       0.596020       0.829999       0.000000\n",
       "0.2       0.818242       0.836871       0.828880       0.328447       0.000000\n",
       "0.4       0.831526       0.829338       0.318217       0.828065       0.832748\n",
       "0.5       0.831068       0.661831       0.827607       0.328447       0.820227\n",
       "0.6       0.353336       0.823586       0.827709       0.830814       0.827556\n",
       "0.8       0.825571       0.724691       0.818344       0.328447       0.000000\n",
       "1.0       0.797272       0.824095       0.828422       0.328447       0.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat(all_accs,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sfdfs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-82b054b92269>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msfdfs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sfdfs' is not defined"
     ]
    }
   ],
   "source": [
    "sfdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_time = pd.concat(all_time,1).sum().sum()\n",
    "n_params = 125238531\n",
    "print(\"Time for all experiments = {:.1f} hours\".format(total_time))\n",
    "print(\"Number of paramaters for RoBERTa = {}\".format(n_params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhos, mean_acc, error_acc, _ = get_rho_stats_from_result_list(all_accs)\n",
    "\n",
    "_, mean_acc_t, error_acc_t, _ = get_rho_stats_from_result_list(all_transformed_accs)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "ax.errorbar(rhos, mean_acc, yerr=error_acc, fmt='-o', label=\"original test data\");\n",
    "ax.errorbar(rhos, mean_acc_t, yerr=error_acc_t, fmt='-o', label=\"transformed test data\");\n",
    "ax.legend(loc=\"best\");\n",
    "ax.set_xlabel(r\"$\\rho$\", fontsize=14);\n",
    "ax.set_ylabel(\"accuracy\", fontsize=14);\n",
    "ax.set_title(\"RoBERTa accuracy\\n\\ndataset: MNLI\\ntransformation: synonym substitution\\ntest repetitions: {}\\n\".format(test_repetitions));\n",
    "fig.tight_layout()\n",
    "fig.savefig('figs/roberta_base_acc_mnli_syn_p_h.png', bbox_inches=None, pad_inches=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhos, mean_p_values, error_p_values, min_p_values = get_rho_stats_from_result_list(all_paired_t_p_values)\n",
    "\n",
    "alpha = 0.05\n",
    "alpha_adj = alpha / test_repetitions\n",
    "\n",
    "rejected_ids = []\n",
    "remain_ids = []\n",
    "\n",
    "for i,p in enumerate(min_p_values):\n",
    "    if p < alpha_adj:\n",
    "        rejected_ids.append(i)\n",
    "    else:\n",
    "        remain_ids.append(i)\n",
    "        \n",
    "rhos_rejected = rhos[rejected_ids]\n",
    "rhos_remain = rhos[remain_ids]\n",
    "y_rejected = mean_p_values[rejected_ids]\n",
    "y_remain = mean_p_values[remain_ids]\n",
    "error_rejected = error_p_values[rejected_ids]\n",
    "error_remain = error_p_values[remain_ids]\n",
    "\n",
    "title_msg = \"RoBERTa p-values\\n\\ndataset:\"\n",
    "title_msg += \"MNLI\\ntransformation: synonym substitution\\ntest repetitions: {}\\n\".format(test_repetitions)\n",
    "title_msg += \"significance level = {:.1%} \\n\".format(alpha)\n",
    "title_msg += \"adjusted significance level = {:.2%} \\n\".format(alpha_adj)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "ax.errorbar(rhos_rejected, y_rejected, yerr=error_rejected, fmt='o', linewidth=0.50, label=\"at least one p-value is smaller than {:.2%}\".format(alpha_adj));\n",
    "ax.errorbar(rhos_remain, y_remain, yerr=error_remain, fmt='o', linewidth=0.50, label=\"all p-values are greater than {:.2%}\".format(alpha_adj));\n",
    "ax.legend(loc=\"best\");\n",
    "ax.set_xlabel(r\"$\\rho$\", fontsize=14);\n",
    "ax.set_ylabel(\"p-value\", fontsize=14);\n",
    "ax.set_title(title_msg);\n",
    "fig.tight_layout()\n",
    "fig.tight_layout()\n",
    "fig.savefig('figs/roberta_p_values_mnli_syn_p_h.png', bbox_inches=None, pad_inches=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhos, diff, _,_ = get_rho_stats_from_result_list(all_dev_plus_diff)\n",
    "_, test_acc, _,_ = get_rho_stats_from_result_list(all_accs)\n",
    "_, test_acc_t, _,_ = get_rho_stats_from_result_list(all_transformed_accs)\n",
    "test_diff = np.abs(test_acc - test_acc_t)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "ax.errorbar(rhos, diff, fmt='-o', label=\"validation\");\n",
    "ax.errorbar(rhos, test_diff, fmt='-o', label=\"test\");\n",
    "\n",
    "ax.legend(loc=\"best\");\n",
    "ax.set_xlabel(r\"$\\rho$\", fontsize=14);\n",
    "ax.set_ylabel(\"average accuracy difference\", fontsize=14);\n",
    "ax.set_title(\"RoBERTa accuracy difference\\n\\ndataset: MNLI\\ntransformation: synonym substitution\\ntest repetitions: {}\\n\".format(test_repetitions));\n",
    "fig.tight_layout()\n",
    "fig.savefig('figs/roberta_acc_diff_mnli_syn_p_h.png', bbox_inches=None, pad_inches=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting the best $\\rho$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_min = np.argmin(diff)\n",
    "min_rho = rhos[id_min]\n",
    "min_rho_test_acc = test_acc[id_min]\n",
    "min_rho_transformed_test_acc = test_acc_t[id_min]\n",
    "test_accuracy_loss_pct = np.round(((min_rho_test_acc  - test_acc[0]) / test_acc[0]) * 100, 1)\n",
    "\n",
    "analysis = {\"dataset\":\"mnli\",\n",
    "            \"model\": \"RoBERTa\",\n",
    "            \"rho\":min_rho,\n",
    "            \"test_accuracy_loss_pct\": test_accuracy_loss_pct,\n",
    "            \"average_test_accuracy\": min_rho_test_acc,\n",
    "            \"average_transformed_test_accuracy\": min_rho_transformed_test_acc,\n",
    "            \"combined_accuracy\": np.mean([min_rho_test_acc,min_rho_transformed_test_acc])}\n",
    "analysis = pd.DataFrame(analysis, index=[0])\n",
    "analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
