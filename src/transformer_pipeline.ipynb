{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lr.models.transformers.util import *\n",
    "import logging\n",
    "import os\n",
    "import shutil\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertForSequenceClassification\n",
    "from time import time\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"toy\"\n",
    "\n",
    "hyperparams = {\"local_rank\": -1,\n",
    "               \"max_seq_length\": 200,\n",
    "               \"overwrite_cache\": False,\n",
    "               \"num_train_epochs\":1.0,\n",
    "               \"per_gpu_train_batch_size\":32,\n",
    "               \"per_gpu_eval_batch_size\":32,\n",
    "               \"gradient_accumulation_steps\": 1,\n",
    "               \"learning_rate\":5e-5,\n",
    "               \"weight_decay\":0.0,\n",
    "               \"adam_epsilon\": 1e-8,\n",
    "               \"max_grad_norm\": 1.0,\n",
    "               \"max_steps\": -1,\n",
    "               \"warmup_steps\": 0,\n",
    "               \"save_steps\": 10,\n",
    "               \"no_cuda\":False,\n",
    "               \"n_gpu\":1,\n",
    "               \"model_name_or_path\":\"bert\",\n",
    "               \"output_dir\":\"bert\",\n",
    "               \"random_state\": 42,\n",
    "               \"fp16\":False,\n",
    "               \"fp16_opt_level\":\"01\",\n",
    "               \"device\":\"cpu\",\n",
    "               \"verbose\":True,\n",
    "               \"model_type\": \"bert\",\n",
    "               \"train_cached_features_file\": \"data/{}/cached_train\".format(folder),\n",
    "               \"dev_cached_features_file\": \"data/{}/cached_dev\".format(folder),\n",
    "               \"train_to_eval_cached_features_file\": \"data/{}/cached_train_to_eval\".format(folder),\n",
    "               \"dev_to_eval_cached_features_file\": \"data/{}/cached_dev_to_eval\".format(folder)} \n",
    "\n",
    "\n",
    "\n",
    "set_seed(hyperparams[\"random_state\"], hyperparams[\"n_gpu\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set results dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_results = {\"moment\":[],\n",
    "                \"type\":[],\n",
    "                \"loss\":[],\n",
    "                \"acc\":[],\n",
    "                \"time\":[]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"data/{}/train.csv\".format(folder)\n",
    "\n",
    "eval_sample_size = 100\n",
    "\n",
    "\n",
    "df = pd.read_csv(train_path)\n",
    "\n",
    "\n",
    "train_test_split\n",
    "df_train, df_dev = train_test_split(df, test_size=0.2)\n",
    "df_train_to_eval = df_train.sample(n=eval_sample_size)\n",
    "df_dev_to_eval = df_dev.sample(n=eval_sample_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = NLIProcessor()\n",
    "train_examples = processor.df2examples(df_train, \"train\")\n",
    "train_examples_to_eval = processor.df2examples(df_train_to_eval, \"train_to_eval\")\n",
    "dev_examples = processor.df2examples(df_dev, \"dev\")\n",
    "dev_examples_to_eval = processor.df2examples(df_dev_to_eval, \"dev_to_eval\")\n",
    "\n",
    "all_examples = [train_examples, train_examples_to_eval,\n",
    "                dev_examples, dev_examples_to_eval]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "tail = \"_{}\".format(hyperparams[\"max_seq_length\"])\n",
    "train_cached_features_file = hyperparams[\"train_cached_features_file\"] + tail\n",
    "dev_cached_features_file = hyperparams[\"dev_cached_features_file\"] + tail\n",
    "train_to_eval_cached_features_file = hyperparams[\"train_to_eval_cached_features_file\"] + tail\n",
    "dev_to_eval_cached_features_file = hyperparams[\"dev_to_eval_cached_features_file\"] + tail\n",
    "\n",
    "paths = [train_cached_features_file,\n",
    "         train_to_eval_cached_features_file,\n",
    "         dev_cached_features_file,\n",
    "         dev_to_eval_cached_features_file]\n",
    "\n",
    "# loading tokenizers\n",
    "pretrained_weights = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(pretrained_weights)\n",
    "label_map = processor.get_label_map()\n",
    "max_seq_length = hyperparams[\"max_seq_length\"]\n",
    "\n",
    "# # creating features\n",
    "\n",
    "for example_set, path in zip(all_examples, paths):\n",
    "    if not os.path.exists(path):\n",
    "        features = convert_examples_to_features(examples=example_set,\n",
    "                                                tokenizer=tokenizer,\n",
    "                                                label_map=label_map,\n",
    "                                                max_length=max_seq_length)\n",
    "        torch.save(features, path)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = features2dataset(train_cached_features_file)\n",
    "train_dataset_to_eval = features2dataset(train_to_eval_cached_features_file)\n",
    "dev_dataset = features2dataset(dev_cached_features_file)\n",
    "dev_dataset_to_eval = features2dataset(dev_to_eval_cached_features_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(pretrained_weights, num_labels = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval before training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 4/4 [00:12<00:00,  3.03s/it]\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_results = evaluate(train_dataset_to_eval, hyperparams, model)\n",
    "train_acc = (train_results.prediction==train_results.label).mean()\n",
    "\n",
    "meta_results[\"moment\"].append(\"before\")\n",
    "meta_results[\"type\"].append(\"train\")\n",
    "meta_results[\"loss\"].append(train_loss)\n",
    "meta_results[\"acc\"].append(train_acc)\n",
    "meta_results[\"time\"].append(np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dev "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 4/4 [00:12<00:00,  3.05s/it]\n"
     ]
    }
   ],
   "source": [
    "dev_loss, results = evaluate(dev_dataset_to_eval, hyperparams, model)\n",
    "dev_acc = (results.prediction==results.label).mean()\n",
    "\n",
    "\n",
    "meta_results[\"moment\"].append(\"before\")\n",
    "meta_results[\"type\"].append(\"dev\")\n",
    "meta_results[\"loss\"].append(dev_loss)\n",
    "meta_results[\"acc\"].append(dev_acc)\n",
    "meta_results[\"time\"].append(np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Iteration:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 1/20 [00:12<03:57, 12.51s/it]\u001b[A\n",
      "Iteration:  10%|█         | 2/20 [00:24<03:44, 12.50s/it]\u001b[A\n",
      "Iteration:  15%|█▌        | 3/20 [00:37<03:31, 12.46s/it]\u001b[A\n",
      "Iteration:  20%|██        | 4/20 [00:49<03:18, 12.44s/it]\u001b[A\n",
      "Iteration:  25%|██▌       | 5/20 [01:02<03:05, 12.40s/it]\u001b[A\n",
      "Iteration:  30%|███       | 6/20 [01:14<02:53, 12.37s/it]\u001b[A\n",
      "Iteration:  35%|███▌      | 7/20 [01:26<02:40, 12.37s/it]\u001b[A\n",
      "Iteration:  40%|████      | 8/20 [01:38<02:28, 12.34s/it]\u001b[A\n",
      "Iteration:  45%|████▌     | 9/20 [01:51<02:15, 12.34s/it]\u001b[A\n",
      "Iteration:  50%|█████     | 10/20 [02:10<02:24, 14.40s/it]\u001b[A\n",
      "Iteration:  55%|█████▌    | 11/20 [02:22<02:03, 13.76s/it]\u001b[A\n",
      "Iteration:  60%|██████    | 12/20 [02:35<01:46, 13.32s/it]\u001b[A\n",
      "Iteration:  65%|██████▌   | 13/20 [02:47<01:31, 13.02s/it]\u001b[A\n",
      "Iteration:  70%|███████   | 14/20 [02:59<01:16, 12.81s/it]\u001b[A\n",
      "Iteration:  75%|███████▌  | 15/20 [03:12<01:03, 12.66s/it]\u001b[A\n",
      "Iteration:  80%|████████  | 16/20 [03:24<00:50, 12.55s/it]\u001b[A\n",
      "Iteration:  85%|████████▌ | 17/20 [03:36<00:37, 12.48s/it]\u001b[A\n",
      "Iteration:  90%|█████████ | 18/20 [03:48<00:24, 12.43s/it]\u001b[A\n",
      "Iteration:  95%|█████████▌| 19/20 [04:01<00:12, 12.40s/it]\u001b[A\n",
      "Iteration: 100%|██████████| 20/20 [04:20<00:00, 13.02s/it]\u001b[A\n",
      "Epoch: 100%|██████████| 1/1 [04:20<00:00, 260.48s/it]\n"
     ]
    }
   ],
   "source": [
    "init = time()\n",
    "global_step, tr_loss = train(train_dataset, model, tokenizer, hyperparams)\n",
    "train_time = time() - init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval After training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 4/4 [00:11<00:00,  2.91s/it]\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_results = evaluate(train_dataset_to_eval, hyperparams, model)\n",
    "train_acc = (train_results.prediction==train_results.label).mean()\n",
    "\n",
    "meta_results[\"moment\"].append(\"after\")\n",
    "meta_results[\"type\"].append(\"train\")\n",
    "meta_results[\"loss\"].append(train_loss)\n",
    "meta_results[\"acc\"].append(train_acc)\n",
    "meta_results[\"time\"].append(train_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 4/4 [00:11<00:00,  2.93s/it]\n"
     ]
    }
   ],
   "source": [
    "dev_loss, results = evaluate(dev_dataset_to_eval, hyperparams, model)\n",
    "dev_acc = (results.prediction==results.label).mean()\n",
    "\n",
    "meta_results[\"moment\"].append(\"after\")\n",
    "meta_results[\"type\"].append(\"dev\")\n",
    "meta_results[\"loss\"].append(dev_loss)\n",
    "meta_results[\"acc\"].append(dev_acc)\n",
    "meta_results[\"time\"].append(train_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_results = pd.DataFrame(meta_results)\n",
    "meta_results.to_csv(\"meta.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>moment</th>\n",
       "      <th>type</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>before</td>\n",
       "      <td>train</td>\n",
       "      <td>1.332663</td>\n",
       "      <td>0.30</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>before</td>\n",
       "      <td>dev</td>\n",
       "      <td>1.261880</td>\n",
       "      <td>0.29</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>after</td>\n",
       "      <td>train</td>\n",
       "      <td>1.051574</td>\n",
       "      <td>0.55</td>\n",
       "      <td>260.497859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>after</td>\n",
       "      <td>dev</td>\n",
       "      <td>1.101638</td>\n",
       "      <td>0.27</td>\n",
       "      <td>260.497859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   moment   type      loss   acc        time\n",
       "0  before  train  1.332663  0.30         NaN\n",
       "1  before    dev  1.261880  0.29         NaN\n",
       "2   after  train  1.051574  0.55  260.497859\n",
       "3   after    dev  1.101638  0.27  260.497859"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
