{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lr.models.transformers.util import load_and_cache_examples\n",
    "from lr.models.transformers.util import train, set_seed\n",
    "from torch.utils.data import TensorDataset\n",
    "import logging\n",
    "import os\n",
    "import shutil\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertForSequenceClassification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = {\"local_rank\": -1,\n",
    "               \"max_seq_length\": 128,\n",
    "               \"overwrite_cache\": False,\n",
    "               \"cached_path\":\"data/toy/\",\n",
    "               \"train_path\": \"data/toy/train.csv\",\n",
    "               \"dev_path\":\"data/toy/dev.csv\",\n",
    "               \"num_train_epochs\":3.0,\n",
    "               \"per_gpu_train_batch_size\":8,\n",
    "               \"per_gpu_eval_batch_size\":8,\n",
    "               \"gradient_accumulation_steps\": 1,\n",
    "               \"learning_rate\":5e-5,\n",
    "               \"weight_decay\":0.0,\n",
    "               \"adam_epsilon\": 1e-8,\n",
    "               \"max_grad_norm\": 1.0,\n",
    "               \"max_steps\": 10,\n",
    "               \"warmup_steps\": 0,\n",
    "               \"save_steps\": 5,\n",
    "               \"no_cuda\":True,\n",
    "               \"n_gpu\":1,\n",
    "               \"model_name_or_path\":\"bert\",\n",
    "               \"output_dir\":\"bert\",\n",
    "               \"random_state\": 42,\n",
    "               \"fp16\":False,\n",
    "               \"fp16_opt_level\":\"01\",\n",
    "               \"device\":\"cpu\",\n",
    "               \"verbose\":False,\n",
    "               \"model_type\": \"bert\"}\n",
    "\n",
    "set_seed(hyperparams[\"random_state\"], hyperparams[\"n_gpu\"])\n",
    "\n",
    "pretrained_weights = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(pretrained_weights)\n",
    "model = BertForSequenceClassification.from_pretrained(pretrained_weights, num_labels = 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = load_and_cache_examples(hyperparams, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_dataset = load_and_cache_examples(hyperparams, tokenizer, evaluate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step, tr_loss = train(train_dataset, model, tokenizer, hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_logs = pd.read_csv(\"bert/log.csv\")\n",
    "\n",
    "a1 = training_logs.loss.rolling(3).mean().iloc[3]\n",
    "a2 = training_logs.loss.rolling(3).mean().iloc[-1]\n",
    "\n",
    "\n",
    "\n",
    "assert a1 > a2\n",
    "assert a1 == 1.3554697434107463\n",
    "assert a2 ==  1.131113092104594\n",
    "assert tr_loss == 1.195960673418912"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"example.log\"):\n",
    "    os.remove(\"example.log\")\n",
    "    \n",
    "    \n",
    "if os.path.exists(\"bert\"):\n",
    "    shutil.rmtree(\"bert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
