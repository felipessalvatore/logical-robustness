{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lr.models.transformers.util import *\n",
    "import logging\n",
    "import os\n",
    "import shutil\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertForSequenceClassification\n",
    "from time import time\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"snli\"\n",
    "\n",
    "hyperparams = {\"local_rank\": -1,\n",
    "               \"max_seq_length\": 200,\n",
    "               \"overwrite_cache\": False,\n",
    "               \"num_train_epochs\":3.0,\n",
    "               \"per_gpu_train_batch_size\":32,\n",
    "               \"per_gpu_eval_batch_size\":32,\n",
    "               \"gradient_accumulation_steps\": 1,\n",
    "               \"learning_rate\":5e-5,\n",
    "               \"weight_decay\":0.0,\n",
    "               \"adam_epsilon\": 1e-8,\n",
    "               \"max_grad_norm\": 1.0,\n",
    "               \"max_steps\": -1,\n",
    "               \"warmup_steps\": 0,\n",
    "               \"save_steps\": 500,\n",
    "               \"no_cuda\":False,\n",
    "               \"n_gpu\":1,\n",
    "               \"model_name_or_path\":\"bert\",\n",
    "               \"output_dir\":\"bert\",\n",
    "               \"random_state\": 42,\n",
    "               \"fp16\":False,\n",
    "               \"fp16_opt_level\":\"01\",\n",
    "               \"device\":\"cpu\",\n",
    "               \"verbose\":True,\n",
    "               \"model_type\": \"bert\",\n",
    "               \"train_cached_features_file\": \"data/{}/base_train_\".format(folder),\n",
    "               \"dev_cached_features_file\": \"data/{}/base_dev_\".format(folder)} \n",
    "\n",
    "\n",
    "set_seed(hyperparams[\"random_state\"], hyperparams[\"n_gpu\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set results dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_results = {\"moment\":[],\n",
    "                \"type\":[],\n",
    "                \"loss\":[],\n",
    "                \"acc\":[],\n",
    "                \"time\":[]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"data/{}/train.csv\".format(folder)\n",
    "\n",
    "df = pd.read_csv(train_path)\n",
    "train_test_split\n",
    "df_train, df_dev = train_test_split(df, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = NLIProcessor()\n",
    "train_examples = processor.df2examples(df_train, \"train\")\n",
    "dev_examples = processor.df2examples(df_dev, \"dev\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_weights = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(pretrained_weights)\n",
    "label_map = processor.get_label_map()\n",
    "max_seq_length = hyperparams[\"max_seq_length\"]\n",
    "\n",
    "train_cached_features_file = hyperparams[\"train_cached_features_file\"]\n",
    "dev_cached_features_file = hyperparams[\"dev_cached_features_file\"]\n",
    "\n",
    "\n",
    "\n",
    "train_features = convert_examples_to_features(examples=train_examples,\n",
    "                                              tokenizer=tokenizer,\n",
    "                                              label_map=label_map,\n",
    "                                              max_length=max_seq_length)\n",
    "\n",
    "\n",
    "dev_features = convert_examples_to_features(examples=dev_examples,\n",
    "                                              tokenizer=tokenizer,\n",
    "                                              label_map=label_map,\n",
    "                                              max_length=max_seq_length)\n",
    "\n",
    "torch.save(train_features, train_cached_features_file)\n",
    "\n",
    "torch.save(dev_features, dev_cached_features_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = features2dataset(train_cached_features_file, hyperparams, evaluate=False)\n",
    "dev_dataset = features2dataset(dev_cached_features_file, hyperparams, evaluate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(pretrained_weights, num_labels = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval before training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 25/25 [00:58<00:00,  2.36s/it]\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_results = evaluate(train_dataset, hyperparams, model)\n",
    "train_acc = (train_results.prediction==train_results.label).mean()\n",
    "\n",
    "meta_results[\"moment\"].append(\"before\")\n",
    "meta_results[\"type\"].append(\"train\")\n",
    "meta_results[\"loss\"].append(train_loss)\n",
    "meta_results[\"acc\"].append(train_acc)\n",
    "meta_results[\"time\"].append(np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dev "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 7/7 [00:14<00:00,  2.11s/it]\n"
     ]
    }
   ],
   "source": [
    "dev_loss, results = evaluate(dev_dataset, hyperparams, model)\n",
    "dev_acc = (results.prediction==results.label).mean()\n",
    "\n",
    "\n",
    "meta_results[\"moment\"].append(\"before\")\n",
    "meta_results[\"type\"].append(\"dev\")\n",
    "meta_results[\"loss\"].append(dev_loss)\n",
    "meta_results[\"acc\"].append(dev_acc)\n",
    "meta_results[\"time\"].append(np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Iteration:   0%|          | 0/25 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 1/25 [00:07<03:10,  7.93s/it]\u001b[A\n",
      "Iteration:   8%|▊         | 2/25 [00:15<03:01,  7.91s/it]\u001b[A\n",
      "Iteration:  12%|█▏        | 3/25 [00:23<02:53,  7.86s/it]\u001b[A\n",
      "Iteration:  16%|█▌        | 4/25 [00:31<02:44,  7.84s/it]\u001b[A\n",
      "Iteration:  20%|██        | 5/25 [00:39<02:36,  7.81s/it]\u001b[A\n",
      "Iteration:  24%|██▍       | 6/25 [00:46<02:28,  7.81s/it]\u001b[A\n",
      "Iteration:  28%|██▊       | 7/25 [00:54<02:20,  7.80s/it]\u001b[A\n",
      "Iteration:  32%|███▏      | 8/25 [01:02<02:12,  7.79s/it]\u001b[A\n",
      "Iteration:  36%|███▌      | 9/25 [01:10<02:04,  7.79s/it]\u001b[A\n",
      "Iteration:  40%|████      | 10/25 [01:18<01:56,  7.79s/it]\u001b[A\n",
      "Iteration:  44%|████▍     | 11/25 [01:25<01:48,  7.78s/it]\u001b[A\n",
      "Iteration:  48%|████▊     | 12/25 [01:33<01:40,  7.77s/it]\u001b[A\n",
      "Iteration:  52%|█████▏    | 13/25 [01:41<01:33,  7.77s/it]\u001b[A\n",
      "Iteration:  56%|█████▌    | 14/25 [01:49<01:25,  7.76s/it]\u001b[A\n",
      "Iteration:  60%|██████    | 15/25 [01:56<01:17,  7.77s/it]\u001b[A\n",
      "Iteration:  64%|██████▍   | 16/25 [02:04<01:09,  7.77s/it]\u001b[A\n",
      "Iteration:  68%|██████▊   | 17/25 [02:12<01:02,  7.77s/it]\u001b[A\n",
      "Iteration:  72%|███████▏  | 18/25 [02:20<00:54,  7.77s/it]\u001b[A\n",
      "Iteration:  76%|███████▌  | 19/25 [02:27<00:46,  7.79s/it]\u001b[A\n",
      "Iteration:  80%|████████  | 20/25 [02:42<00:49,  9.94s/it]\u001b[A\n",
      "Iteration:  84%|████████▍ | 21/25 [02:50<00:37,  9.29s/it]\u001b[A\n",
      "Iteration:  88%|████████▊ | 22/25 [02:58<00:26,  8.85s/it]\u001b[A\n",
      "Iteration:  92%|█████████▏| 23/25 [03:06<00:17,  8.53s/it]\u001b[A\n",
      "Iteration:  96%|█████████▌| 24/25 [03:14<00:08,  8.30s/it]\u001b[A\n",
      "Iteration: 100%|██████████| 25/25 [03:21<00:00,  8.07s/it]\u001b[A\n",
      "Epoch: 100%|██████████| 1/1 [03:21<00:00, 201.86s/it]\n"
     ]
    }
   ],
   "source": [
    "init = time()\n",
    "global_step, tr_loss = train(train_dataset, model, tokenizer, hyperparams)\n",
    "train_time = time() - init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval After training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 25/25 [00:58<00:00,  2.34s/it]\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_results = evaluate(train_dataset, hyperparams, model)\n",
    "train_acc = (train_results.prediction==train_results.label).mean()\n",
    "\n",
    "meta_results[\"moment\"].append(\"after\")\n",
    "meta_results[\"type\"].append(\"train\")\n",
    "meta_results[\"loss\"].append(train_loss)\n",
    "meta_results[\"acc\"].append(train_acc)\n",
    "meta_results[\"time\"].append(train_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 7/7 [00:14<00:00,  2.09s/it]\n"
     ]
    }
   ],
   "source": [
    "dev_loss, results = evaluate(dev_dataset, hyperparams, model)\n",
    "dev_acc = (results.prediction==results.label).mean()\n",
    "\n",
    "meta_results[\"moment\"].append(\"after\")\n",
    "meta_results[\"type\"].append(\"dev\")\n",
    "meta_results[\"loss\"].append(dev_loss)\n",
    "meta_results[\"acc\"].append(dev_acc)\n",
    "meta_results[\"time\"].append(train_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_results = pd.DataFrame(meta_results)\n",
    "meta_results.to_csv(\"meta.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
