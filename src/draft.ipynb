{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "\n",
    "from lr.stats.h_testing import DGP\n",
    "from lr.stats.h_testing import get_matched_results\n",
    "from lr.stats.h_testing import get_paired_t_statistic\n",
    "from lr.stats.h_testing import get_cochran_statistic\n",
    "from lr.stats.h_testing import get_boots_series_under_H0\n",
    "from lr.stats.h_testing import get_boot_paired_t_p_value\n",
    "from lr.stats.h_testing import get_boot_cochran_p_value\n",
    "\n",
    "from lr.models.xgb import XGBCWrapper\n",
    "from lr.training.language_representation import Tfidf\n",
    "from lr.text_processing.util import pre_process_nli_df\n",
    "from lr.training.util import get_ternary_label, filter_df_by_label\n",
    "from lr.text_processing.transformations.wordnet import path_base_transformation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"data/snli/train.csv\"\n",
    "dev_path = \"data/snli/dev.csv\"\n",
    "test_path = \"data/snli/test.csv\"\n",
    "\n",
    "train_path_mod = \"data/snli/train_p_h_syn_noun.csv\"\n",
    "dev_path_mod = \"data/snli/dev_p_h_syn_noun.csv\"\n",
    "test_path_mod = \"data/snli/test_p_h_syn_noun.csv\"\n",
    "\n",
    "verbose = True\n",
    "n_jobs = 4\n",
    "search_seed = 455\n",
    "random_state_train = 3456\n",
    "random_state_boot = 123\n",
    "max_features = None\n",
    "dgp_seed = 342\n",
    "rho = 0.0\n",
    "number_of_simulations = 1000\n",
    "\n",
    "search_path = \"hyperparams/xgb_snli/search_{}.csv\".format(search_seed)\n",
    "assert os.path.exists(search_path)\n",
    "\n",
    "\n",
    "transformation_name = \"wordnet syn tranformation p and h\"\n",
    "output_raw_result = \"raw_results/snli/xgb/syn_p_h/rho_{}_results\".format(rho)\n",
    "output_raw_result = output_raw_result.replace(\".\", \"p\") + \".csv\"\n",
    "output_result = \"results/snli/xgb/syn_p_h/rho_{}_results\".format(rho)\n",
    "output_result = output_result.replace(\".\", \"p\") + \".csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_test = time()\n",
    "\n",
    "train = pd.read_csv(train_path)\n",
    "dev = pd.read_csv(dev_path)\n",
    "test = pd.read_csv(test_path)\n",
    "\n",
    "train = filter_df_by_label(train.dropna()).reset_index(drop=True)\n",
    "dev = filter_df_by_label(dev.dropna()).reset_index(drop=True)\n",
    "test = filter_df_by_label(test.dropna()).reset_index(drop=True)\n",
    "\n",
    "pre_process_nli_df(train)\n",
    "pre_process_nli_df(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get hyperarams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_keys = ['n_estimators', 'max_depth', \"reg_alpha\",\n",
    "               \"reg_gamma\", \"learning_rate\", \"subsample\", \"colsample_bytree\"]\n",
    "\n",
    "hyperparams = {\"RepresentationFunction\": Tfidf,\n",
    "               \"n_jobs\": n_jobs,\n",
    "               \"max_features\": max_features,\n",
    "               \"label_translation\": get_ternary_label,\n",
    "               \"data_set_name\": \"snli\",\n",
    "               \"transformation_name\": transformation_name,\n",
    "               \"rho\": rho,\n",
    "               \"model_name_or_path\": \"gradient boosting\",\n",
    "               \"number_of_simulations\": number_of_simulations,\n",
    "               \"search_random_state\": search_seed,\n",
    "               \"dgp_random_state\": dgp_seed,\n",
    "               \"train_random_state\": random_state_train,\n",
    "               \"boot_random_state\": random_state_boot,\n",
    "               \"output_raw_result\": output_raw_result,\n",
    "               \"output_result\": output_result,\n",
    "               \"verbose\": verbose}\n",
    "\n",
    "search_results = pd.read_csv(search_path) \n",
    "               \n",
    "for k in params_keys:\n",
    "    hyperparams[k] = search_results.loc[0,k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set transformed version of the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_trans(df): return path_base_transformation(df, train_path_mod)\n",
    "\n",
    "def dev_trans(df): return path_base_transformation(df, dev_path_mod)\n",
    "\n",
    "def test_trans(df): return path_base_transformation(df, test_path_mod)\n",
    "\n",
    "dgp_train = DGP(data=train,\n",
    "                transformation=train_trans,\n",
    "                rho=rho)\n",
    "\n",
    "dgp_dev = DGP(data=dev,\n",
    "              transformation=dev_trans,\n",
    "              rho=rho)\n",
    "\n",
    "dgp_random_state = hyperparams[\"dgp_random_state\"]\n",
    "\n",
    "train_t = dgp_train.sample(random_state=dgp_random_state)\n",
    "dev_t = dgp_dev.sample(random_state=dgp_random_state)\n",
    "test_t = test_trans(test)\n",
    "\n",
    "# we will train the xgb with train and dev data\n",
    "full_train_t = pd.concat([train_t, dev_t]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBCWrapper(hyperparams)\n",
    "init_train = time()\n",
    "model.fit(full_train_t)\n",
    "train_time =  time() - init_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get matched eval and relevant statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_results = get_matched_results(test,\n",
    "                                test_t,\n",
    "                                model,\n",
    "                                hyperparams[\"label_translation\"])\n",
    "\n",
    "\n",
    "test_acc = m_results.A.mean()\n",
    "transformed_test_acc = m_results.B.mean()\n",
    "t_obs, acc_diff, test_size, standart_error = get_paired_t_statistic(m_results)\n",
    "cochran_obs = get_cochran_statistic(m_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get p-values by bootstrap replications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_simulations = hyperparams[\"number_of_simulations\"]\n",
    "boot_random_state =  hyperparams[\"boot_random_state\"]\n",
    "\n",
    "def get_paired_t(matched_results):\n",
    "    t_obs, _, _, _ = get_paired_t_statistic(matched_results)\n",
    "    return t_obs \n",
    "\n",
    "paired_t_boots = get_boots_series_under_H0(m_results,\n",
    "                                           get_paired_t,\n",
    "                                           number_of_simulations,\n",
    "                                           boot_random_state)\n",
    "\n",
    "\n",
    "\n",
    "cochran_boots = get_boots_series_under_H0(m_results,\n",
    "                                          get_cochran_statistic,\n",
    "                                          number_of_simulations,\n",
    "                                          boot_random_state)\n",
    "\n",
    "\n",
    "paired_t_p_value = get_boot_paired_t_p_value(paired_t_boots, t_obs)\n",
    "\n",
    "cochran_p_value = get_boot_cochran_p_value(cochran_boots, cochran_obs)\n",
    "\n",
    "htest_time = time() - init_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate all results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>model</th>\n",
       "      <th>transformation</th>\n",
       "      <th>rho</th>\n",
       "      <th>search_random_state</th>\n",
       "      <th>dgp_random_state</th>\n",
       "      <th>train_random_state</th>\n",
       "      <th>boot_random_state</th>\n",
       "      <th>number_of_simulations</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>transformed_test_accuracy</th>\n",
       "      <th>accuracy_difference</th>\n",
       "      <th>test_size</th>\n",
       "      <th>standart_error</th>\n",
       "      <th>observable_paired_t_stats</th>\n",
       "      <th>paired_t_p_value</th>\n",
       "      <th>observable_cochran_stats</th>\n",
       "      <th>cochran_p_value</th>\n",
       "      <th>training_time</th>\n",
       "      <th>test_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>snli</td>\n",
       "      <td>gradient boosting</td>\n",
       "      <td>wordnet syn tranformation p and h</td>\n",
       "      <td>0.0</td>\n",
       "      <td>455</td>\n",
       "      <td>342</td>\n",
       "      <td>3456</td>\n",
       "      <td>123</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.607085</td>\n",
       "      <td>0.583062</td>\n",
       "      <td>0.024023</td>\n",
       "      <td>9824</td>\n",
       "      <td>0.694641</td>\n",
       "      <td>3.427739</td>\n",
       "      <td>0.004</td>\n",
       "      <td>11.735356</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.027086</td>\n",
       "      <td>0.035495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   data              model                     transformation  rho  \\\n",
       "0  snli  gradient boosting  wordnet syn tranformation p and h  0.0   \n",
       "\n",
       "   search_random_state  dgp_random_state  train_random_state  \\\n",
       "0                  455               342                3456   \n",
       "\n",
       "   boot_random_state  number_of_simulations  test_accuracy  \\\n",
       "0                123                   1000       0.607085   \n",
       "\n",
       "   transformed_test_accuracy  accuracy_difference  test_size  standart_error  \\\n",
       "0                   0.583062             0.024023       9824        0.694641   \n",
       "\n",
       "   observable_paired_t_stats  paired_t_p_value  observable_cochran_stats  \\\n",
       "0                   3.427739             0.004                 11.735356   \n",
       "\n",
       "   cochran_p_value  training_time  test_time  \n",
       "0            0.002       0.027086   0.035495  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_ = {\"data\": [hyperparams[\"data_set_name\"]],\n",
    "         \"model\": [hyperparams[\"model_name_or_path\"]],\n",
    "         \"transformation\": [hyperparams[\"transformation_name\"]],\n",
    "         \"rho\": [rho],\n",
    "         \"search_random_state\": [hyperparams[\"search_random_state\"]],\n",
    "         \"dgp_random_state\": [dgp_random_state],\n",
    "         \"train_random_state\": [hyperparams[\"train_random_state\"]],\n",
    "         \"boot_random_state\": [boot_random_state],\n",
    "         \"number_of_simulations\": [number_of_simulations],\n",
    "         \"test_accuracy\": [test_acc],\n",
    "         \"transformed_test_accuracy\": [transformed_test_acc],\n",
    "         \"accuracy_difference\": [acc_diff],\n",
    "         \"test_size\": [test_size],\n",
    "         \"standart_error\": [standart_error],\n",
    "         \"observable_paired_t_stats\": [t_obs],\n",
    "         \"paired_t_p_value\": [paired_t_p_value],\n",
    "         \"observable_cochran_stats\": [cochran_obs],\n",
    "         \"cochran_p_value\": [cochran_p_value],\n",
    "         \"training_time\": [train_time / 3600],\n",
    "         \"test_time\": [htest_time / 3600]}\n",
    "\n",
    "test_results = pd.DataFrame(dict_)\n",
    "m_results.to_csv(output_raw_result, index=False)\n",
    "test_results.to_csv(output_result, index=False)\n",
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
